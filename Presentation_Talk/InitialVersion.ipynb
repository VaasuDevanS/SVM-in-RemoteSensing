{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Support_Vector_Machine.ipynb","version":"0.3.2","provenance":[{"file_id":"1lw-Dg_CuiuLo-gXzQBiSoamiNHuD0TT0","timestamp":1553271817685}],"private_outputs":true,"collapsed_sections":["nOA6QhtI4Ilf","1tU7fliBES2y","mFZ6r8rj4Uxv","i8WqCo11ez1u","6VHaVkH75J_h","tq0QB5kL5RMZ","xCAB5zpM5TOh"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"LGPzJkVi1aqW","colab_type":"text"},"cell_type":"markdown","source":["\n","\n",">>>>>> ![alt text](https://lms.unb.ca/d2l/lp/navbars/6606/theme/viewimage/1011374/view?v=10.8.11.15344-90)\n","\n","\n",">>># GGE 6322: IMAGE PROCESSING AND COMPUTER VISION\n","\n","---\n","\n",">>>>>>>>## Support Vector Machine\n","\n",">>>>>### By Vaasudevan Srinivasan presented on **March 26, 2019 09:30**"]},{"metadata":{"id":"nOA6QhtI4Ilf","colab_type":"text"},"cell_type":"markdown","source":["# 1.) A Gentle introduction to Classification and its jargons"]},{"metadata":{"id":"J01UrT5_6ZIm","colab_type":"text"},"cell_type":"markdown","source":["## What is Classification ?\n","\n","**Classification** is the problem of identifying to which of a set of categories (sub-populations) a **new observation** belongs, on the **basis of a training set of data** containing observations (or instances) whose **category membership is known.**\n","\n","---\n","## Classifier What?\n","\n","An **algorithm** that implements classification, especially in a concrete implementation, is known as a **classifier**. The term \"classifier\" sometimes also refers to the **mathematical function**, implemented by a classification algorithm, that maps input data to a category. \n","\n","---"]},{"metadata":{"id":"cL8M0piDMkkO","colab_type":"text"},"cell_type":"markdown","source":["## Features and Regions\n","\n","A crude but **functional definition** of a feature is something that can be **measured\n","in an image**. A feature is therefore a number or a set of numbers derived\n","from a digital image.\n","\n","Features are associated with **image regions**. An object within an image has\n","a set of measurements (features) that can be used to characterize it.\n","\n","---"]},{"metadata":{"id":"PQ1t30biMvUK","colab_type":"text"},"cell_type":"markdown","source":["## Training and Testing\n","\"It is **standard practice** to measure and classify a set of data to establish a\n","normal range for the features to be used in automatic classification. This is what\n","is referred to as **training**, and it is an essential part of building a recognition.\"\n","\n","---"]},{"metadata":{"id":"ZKqBbxXV-zRH","colab_type":"text"},"cell_type":"markdown","source":["## Class\n","**One of a set of enumerated target values for a label**. For example, in a binary classification model that detects spam, the two classes are **spam and not spam**. In a multi-class classification model that identifies dog breeds, the classes would be **poodle, beagle, pug**, and so on.\n","\n","Classification = **Class** - ification\n","\n","---"]},{"metadata":{"id":"PTXVHqzSGsMQ","colab_type":"text"},"cell_type":"markdown","source":["## Classification model\n","A type of machine learning model for distinguishing among two or more discrete classes.\n","\n","---"]},{"metadata":{"id":"6W1MtUugGvfg","colab_type":"text"},"cell_type":"markdown","source":["## Decision Boundary\n","The **separator** between classes learned by a model in a binary class or multi-class classification problems.\n","\n","![alt text](https://developers.google.com/machine-learning/glossary/images/decision_boundary.png)"]},{"metadata":{"id":"0p7jyv4dG2Ny","colab_type":"text"},"cell_type":"markdown","source":["## Confusion matrix\n","An **NxN table** that summarizes how successful a classification model's predictions were..!!\n","\n","![alt text](https://se.mathworks.com/matlabcentral/mlc-downloads/downloads/submissions/60900/versions/13/screenshot.png =400x250)\n","\n","### Precision:\n","Precision identifies the frequency with which a model was correct when predicting the positive class.\n","$\\text{Precision} =\n","\\frac{\\text{True Positives}} {\\text{True Positives} + \\text{False Positives}}$\n","\n","### Recall:\n","Out of all the possible positive labels, how many did the model correctly identify?\n","$\\text{Recall} =\n","\\frac{\\text{True Positives}} {\\text{True Positives} + \\text{False Negatives}}$\n","\n","### Accuracy:\n","The fraction of predictions that a classification model got right.\n","$\\text{Accuracy} =\n","\\frac{\\text{Correct Predictions}} {\\text{Total Number Of Examples}}$\n","\n","\n","![alt text](https://cdn-images-1.medium.com/max/1600/1*olyfFzeb17lHGad2ht-1GQ.jpeg =500x350)\n","\n","---"]},{"metadata":{"id":"1tU7fliBES2y","colab_type":"text"},"cell_type":"markdown","source":["# 2.) Types of Classification"]},{"metadata":{"id":"tcZOYRUBHGPq","colab_type":"text"},"cell_type":"markdown","source":["### 1.) Logistic Regression\n","\n","Logistic regression is kind of like linear regression but is used when the dependent variable is not a number, but something else (like a Yes/No response)\n","\n","![alt text](https://cdn-images-1.medium.com/max/1600/1*FjhVxyGH9RQ9S-EgqwcuCw.png)\n","\n","---"]},{"metadata":{"id":"wzbIpE8ZWDZ5","colab_type":"text"},"cell_type":"markdown","source":["### 2.) K-Nearest Neighbours (K-NN)\n","\n","K-NN algorithm is one of the **simplest classification algorithm** and it is used to identify the data points that are separated into several classes to predict the classification of a new sample point. K-NN is a non-parametric, **lazy learning algorithm**. It classifies new cases based on a **similarity measure** (e.g. distance functions).\n","\n","Some of the distance metrics that are mentioned in the book are:\n","\n","* Pythagorean distance\n","* Manhattan distance or city block distance\n","* Mahanalobis distance\n","\n","---"]},{"metadata":{"id":"tdR-MCeIWHjI","colab_type":"text"},"cell_type":"markdown","source":["### 3.) Naive Bayes\n","\n","Naive Bayes classifier is based on Bayesâ€™ theorem with the independence assumptions between predictors.\n","\n","![alt text](https://cdn-images-1.medium.com/max/1600/1*Nl2VnCXSzcZ6mW1TZMYrrQ.png)\n","\n","\n","---"]},{"metadata":{"id":"dhMzqnC6WKaQ","colab_type":"text"},"cell_type":"markdown","source":["### 4.) Decision Tree Classification\n","\n","Decision tree builds** classification or regression models in the form of a tree structure**. It breaks down a dataset into **smaller and smaller subsets** while at the same time an associated decision tree is incrementally developed. The final result is a **tree with decision nodes and leaf nodes**.\n","\n","![alt text](https://cdn-images-1.medium.com/max/1600/1*OqOzEP0pLmqvEBirKAjPXQ.png)\n","\n","---"]},{"metadata":{"id":"mFZ6r8rj4Uxv","colab_type":"text"},"cell_type":"markdown","source":["# 3.) Support Vector Machines"]},{"metadata":{"id":"i8WqCo11ez1u","colab_type":"text"},"cell_type":"markdown","source":["## What is SVM ?\n","Support Vector is used for **both regression and Classification**. It is based on the concept of decision planes that define decision boundaries. A decision plane(hyperplane) is one that separates between a set of objects having different class memberships.\n","\n","# A support vector machine (SVM) is a nitro-powered version of such a linear discriminant\n","\n","![alt text](https://cdn-images-1.medium.com/max/1600/1*95CpEn5emttSS5e0fUsrUA.png)\n"]},{"metadata":{"id":"NWDokiCvfd-u","colab_type":"text"},"cell_type":"markdown","source":["### How it works ?\n","It performs classification by finding the hyperplane that maximizes the margin between the two classes with the help of support vectors.\n","\n","![alt text](https://cdn-images-1.medium.com/max/800/1*2ojyZD4JWaYKXwdK7-ONTw.png)"]},{"metadata":{"id":"xODSMxmZj4H7","colab_type":"text"},"cell_type":"markdown","source":["## Kernels\n","\n","Types of kernel function are:\n","\n","![alt text](https://cdn-images-1.medium.com/max/1600/1*t5pCjO0AojDMjKkJUMZ6gw.gif)\n","\n","\n","\n","\n"]},{"metadata":{"id":"dYJTNIYPwpoy","colab_type":"text"},"cell_type":"markdown","source":["# 4.) Paramter Optimisation"]},{"metadata":{"id":"6VHaVkH75J_h","colab_type":"text"},"cell_type":"markdown","source":["# 5.) Code Along (Results and Conclusions)"]},{"metadata":{"id":"FGN1fuY1kI9t","colab_type":"code","colab":{}},"cell_type":"code","source":["# Importing the modules\n","from skimage import data, filters\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2"],"execution_count":0,"outputs":[]},{"metadata":{"id":"abZqy0p2kSvI","colab_type":"code","colab":{}},"cell_type":"code","source":["image = data.coins()\n","edges = filters.sobel(image)\n","plt.imshow(edges)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tq0QB5kL5RMZ","colab_type":"text"},"cell_type":"markdown","source":["# 6.) Conclusion"]},{"metadata":{"id":"Q_RdQXVymB3Q","colab_type":"text"},"cell_type":"markdown","source":["## SVM"]},{"metadata":{"id":"xCAB5zpM5TOh","colab_type":"text"},"cell_type":"markdown","source":["# References"]},{"metadata":{"id":"f4nVpceA84AI","colab_type":"text"},"cell_type":"markdown","source":["*  Algorithms for Image Processing and Computer Vision Second Edition by J.R. Parker ([pdf](http://www.manalhelal.com/Books/crol/Algorithms%20for%20Image%20Processing%20and%20Computer%20Vision_2011.pdf))\n","*   https://en.wikipedia.org/wiki/Statistical_classification\n","*   https://developers.google.com/machine-learning/glossary/\n","*   https://towardsdatascience.com/supervised-machine-learning-classification-5e685fe18a6d\n","\n"]}]}